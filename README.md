# ðŸ” RAG Document Intelligence

A production-grade **Retrieval-Augmented Generation** system that ingests PDF documents into vector embeddings and answers questions using hybrid semantic + keyword search with re-ranking.

Built with **LangChain**, **ChromaDB**, **OpenAI**, **FastAPI**, and **Streamlit**.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG Document Intelligence                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”‚                                          â”‚
â”‚   ðŸ“„ Ingestion       â”‚   ðŸ” Query Pipeline                     â”‚
â”‚                      â”‚                                          â”‚
â”‚   PDF Upload/Dir â”€â”€â–º â”‚   User Question                          â”‚
â”‚         â”‚            â”‚        â”‚                                  â”‚
â”‚   PyPDF Loader       â”‚        â–¼                                  â”‚
â”‚         â”‚            â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   Recursive          â”‚   â”‚ Semantic â”‚    â”‚ Keyword  â”‚           â”‚
â”‚   Text Splitter      â”‚   â”‚ Search   â”‚    â”‚ Search   â”‚           â”‚
â”‚         â”‚            â”‚   â”‚(ChromaDB)â”‚    â”‚ (BM25)   â”‚           â”‚
â”‚   OpenAI             â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   Embeddings         â”‚        â”‚               â”‚                  â”‚
â”‚         â”‚            â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚   ChromaDB           â”‚                â”‚                          â”‚
â”‚   Vector Store       â”‚     Reciprocal Rank Fusion                â”‚
â”‚                      â”‚                â”‚                          â”‚
â”‚                      â”‚         Re-ranked Results                 â”‚
â”‚                      â”‚                â”‚                          â”‚
â”‚                      â”‚        GPT-4o-mini + Context              â”‚
â”‚                      â”‚                â”‚                          â”‚
â”‚                      â”‚     Answer with Source Citations           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   ðŸŒ FastAPI REST API          ðŸ“Š Streamlit Frontend            â”‚
â”‚   POST /ask                    Interactive Document Q&A          â”‚
â”‚   POST /upload                 PDF Upload & Ingestion            â”‚
â”‚   POST /search                 Search Controls & Results         â”‚
â”‚   POST /ingest                 Source Attribution View           â”‚
â”‚   GET  /stats                                                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **Hybrid Search** â€” Combines semantic vector search (ChromaDB) with BM25 keyword search for robust retrieval
- **Reciprocal Rank Fusion** â€” Merges results from multiple retrieval methods using the RRF algorithm
- **Source Attribution** â€” Every answer includes cited sources with filename and page numbers
- **Deduplication** â€” Content-hash based dedup prevents duplicate embeddings
- **REST API** â€” Full FastAPI backend with OpenAPI docs, file upload, and search endpoints
- **Interactive UI** â€” Streamlit frontend for document upload, Q&A, and retrieval-only search
- **CLI Ingestion** â€” Command-line tool for batch document processing
- **Configurable** â€” All parameters (chunk size, top-k, models) via environment variables

## Tech Stack

| Component | Technology |
|-----------|-----------|
| LLM | OpenAI GPT-4o-mini |
| Embeddings | OpenAI text-embedding-3-small |
| Vector DB | ChromaDB |
| Framework | LangChain |
| API | FastAPI + Uvicorn |
| Frontend | Streamlit |
| Search | BM25 (rank-bm25) + Cosine Similarity |
| Re-ranking | Reciprocal Rank Fusion |
| PDF Processing | PyPDF |

## ðŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/salehA13/rag-document-intelligence.git
cd rag-document-intelligence

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### 2. Configure

```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
```

### 3. Ingest Documents

```bash
# Ingest sample docs
python ingest.py ./docs

# Ingest a single PDF
python ingest.py path/to/document.pdf

# Check stats
python ingest.py --stats .
```

### 4. Start the API

```bash
uvicorn src.api.server:app --reload --port 8000
```

API docs available at: http://localhost:8000/docs

### 5. Launch the UI

```bash
streamlit run src/frontend/app.py
```

## ðŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/stats` | Vector store statistics |
| `POST` | `/ask` | Ask a question (full RAG pipeline) |
| `POST` | `/search` | Search documents (retrieval only) |
| `POST` | `/upload` | Upload and ingest a PDF |
| `POST` | `/ingest` | Ingest all PDFs from a directory |

### Example: Ask a Question

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the self-attention mechanism?", "top_k": 10, "rerank_k": 5}'
```

```json
{
  "answer": "The self-attention mechanism is the core innovation of transformers...",
  "sources": [
    {"filename": "transformer_survey.pdf", "page": 0}
  ],
  "num_sources": 5
}
```

## ðŸ§ª Testing

```bash
pip install pytest
pytest tests/ -v
```

## ðŸ“‚ Project Structure

```
rag-document-intelligence/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # Centralized settings (pydantic-settings)
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ loader.py          # PDF loading & text chunking
â”‚   â”‚   â””â”€â”€ embedder.py        # Vector store management
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ hybrid.py          # Hybrid search + RRF re-ranking
â”‚   â”‚   â””â”€â”€ qa.py              # QA chain with source attribution
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ models.py          # Pydantic request/response models
â”‚   â”‚   â””â”€â”€ server.py          # FastAPI application
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ app.py             # Streamlit UI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_loader.py
â”‚   â”œâ”€â”€ test_search.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ docs/                      # Sample PDFs
â”œâ”€â”€ ingest.py                  # CLI ingestion tool
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Screenshots

> _Launch the Streamlit UI to see the interactive document Q&A interface._

| Feature | Description |
|---------|-------------|
| ðŸ“„ Document Upload | Drag & drop PDFs in the sidebar |
| ðŸ’¬ Q&A Interface | Ask questions with adjustable search parameters |
| ðŸ”Ž Search Mode | Retrieval-only mode with expandable results |
| ðŸ“‘ Source Citations | Every answer shows source documents and pages |

## How It Works

1. **Ingestion** â€” PDFs are loaded with PyPDF, split into overlapping chunks using LangChain's RecursiveCharacterTextSplitter, embedded with OpenAI, and stored in ChromaDB
2. **Retrieval** â€” Queries trigger both semantic search (cosine similarity on embeddings) and BM25 keyword search, then results are fused using Reciprocal Rank Fusion
3. **Generation** â€” Top-ranked chunks are formatted with source metadata and sent to GPT-4o-mini with a system prompt enforcing grounded, cited answers

## License

MIT

---

Built by [Saleh](https://github.com/salehA13)
